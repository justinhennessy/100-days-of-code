{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import random\n",
    "from fastai.imports import *\n",
    "from fastai.structured import *\n",
    "from matplotlib import pyplot\n",
    "from pandas_summary import DataFrameSummary\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from IPython.display import display\n",
    "from tabulate import tabulate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scipy.stats import trim_mean, kurtosis\n",
    "from scipy.stats.mstats import mode, gmean, hmean\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn import metrics\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import f1_score,\\\n",
    "    accuracy_score, confusion_matrix,\\\n",
    "    precision_score, recall_score,\\\n",
    "    roc_curve, roc_auc_score,\\\n",
    "    cohen_kappa_score, mean_absolute_error,\\\n",
    "    precision_recall_curve, auc,\\\n",
    "    average_precision_score\n",
    "\n",
    "set_plot_sizes(12,14,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df_raw):\n",
    "    # Sort data by date\n",
    "    df_raw = df_raw.sort_values(by='licence_registration_date')\n",
    "    \n",
    "    # Convert annual_revenue from a string to a float\n",
    "    df_raw['annual_revenue'] = pd.to_numeric(df_raw['annual_revenue'].str.replace(',', ''))\n",
    "    \n",
    "    # Convert fields to INT and setting any NaNs to the mean of that type\n",
    "    case_types = ['cases_total','cases_open','cases_closed','cases_age_hours_total','cases_age_hours_average', 'last_login_days']\n",
    "\n",
    "    for case_type in case_types:\n",
    "        default_value = df_raw[case_type].fillna(df_raw[case_type].median())\n",
    "        df_raw[case_type] = df_raw[case_type].fillna(default_value).astype(int)\n",
    "    \n",
    "    # Fix missing values for annual revenue, replace with mean/trimmed mean of the plan size they are on\n",
    "    plan_list = df_raw.plan[~pd.isnull(df_raw.plan)].unique()\n",
    "\n",
    "    for plan in plan_list:\n",
    "        mean = round(df_raw.annual_revenue[df_raw.plan == plan].mean(), 2)\n",
    "        trimmed_mean = trim_mean(df_raw.annual_revenue[df_raw.plan == plan].values, 0.1)\n",
    "    \n",
    "        if pd.isnull(mean):\n",
    "            revenue = 0\n",
    "        else:\n",
    "            revenue = mean\n",
    "        df_raw.loc[df_raw.plan==plan, 'annual_revenue'] = df_raw.loc[df_raw.plan==plan, 'annual_revenue'].fillna(revenue)\n",
    "        \n",
    "    # 'bin' last login days\n",
    "\n",
    "    bins = [1, 3, 7, 14, 30, 60]\n",
    "    group_names = ['day', 'few_days', 'week', 'fortnight', 'month']\n",
    "\n",
    "    # need to get the mean of the plan size for last_login_days and set each row to that\n",
    "    #df_raw.last_login_days = df_raw.last_login_days.fillna(np.mean(df_raw.last_login_days))\n",
    "\n",
    "    last_login_categories = pd.cut(df_raw['last_login_days'], bins, labels=group_names)\n",
    "    df_raw['last_login_categories'] = pd.cut(df_raw['last_login_days'], bins, labels=group_names)\n",
    "    #pd.value_counts(df_raw['last_login_categories'])\n",
    "    \n",
    "    # one-hot encode fields\n",
    "    dummy_columns = ['customer_account_status', 'last_login_categories', 'plan']\n",
    "\n",
    "    for dummy_column in dummy_columns:\n",
    "        dummy = pd.get_dummies(df_raw[dummy_column], prefix=dummy_column)\n",
    "        df_raw = pd.concat([df_raw,dummy], axis=1)\n",
    "        df_raw = df_raw.drop(columns=dummy_column)\n",
    "        \n",
    "    \n",
    "    # This breaks all the date features up into number columns\n",
    "    # These steps can only be run once then you need to comment them out\n",
    "    add_datepart(df_raw, 'licence_registration_date')\n",
    "    add_datepart(df_raw, 'golive_date')\n",
    "    \n",
    "    # Drop columns, some of these create \"Data Leakage\", some are just to test if it has impact when they are taken out\n",
    "    df_raw = df_raw.drop(columns=['customer_account_status_Good', 'last_login_concern',\n",
    "                                  'last_login_days', 'account_status', 'changing_platform', \n",
    "                                  'new_platform', 'licence_status', 'canceldate', \n",
    "                                  'cancel_details', 'cancel_reason'])\n",
    "    \n",
    "    # Set default values for NaN values in NPS\n",
    "    df_raw.nps = df_raw.nps.fillna(np.nanmean(df_raw.nps))\n",
    "\n",
    "    # Set NaN to zero\n",
    "    features = ['churned', 'interactions_total', 'interactions_completed', 'interactions_no_response', 'interactions_no_onboarding', 'interactions_completed_training']\n",
    "\n",
    "    for feature in features:\n",
    "        df_raw[feature] = df_raw[feature].fillna(0)\n",
    "        \n",
    "    # Complete the transformation of all data into numbers using proc_df and create training dataframes\n",
    "    train_cats(df_raw)\n",
    "    \n",
    "    return df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in data\n",
    "\n",
    "PATH = \"../../data/\"\n",
    "df_raw = pd.read_csv(f'{PATH}churn.csv', low_memory=False, \n",
    "                     parse_dates=['canceldate', 'licence_registration_date', 'golive_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2780 (2780, 38)\n",
      "5889 (5889, 99)\n",
      "5889 (5889, 103)\n"
     ]
    }
   ],
   "source": [
    "print(len(df_raw[df_raw.churned == 0]), df_raw[df_raw.churned == 0].shape)\n",
    "df_processed = prepare_data(df_raw)\n",
    "print(len(df_processed), df_processed.shape)\n",
    "df_data, y_data, nas = proc_df(df_processed, 'churned')\n",
    "print(len(df_data), df_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2780 1631\n"
     ]
    }
   ],
   "source": [
    "joblib_file = \"churn_model.pkl\"\n",
    "\n",
    "# Load from file\n",
    "churn_model = joblib.load(joblib_file)\n",
    "\n",
    "predictions = churn_model.predict(df_data)\n",
    "\n",
    "array = []\n",
    "for i in range(len(df_raw[df_raw.churned == 0].username)):\n",
    "    if predictions[i] == 1:\n",
    "        array.append([df_raw[df_raw.churned == 0].username.iloc[i],predictions[i]])\n",
    "        \n",
    "\n",
    "print(len(df_raw[df_raw.churned == 0]), len(array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/1292bacee4b6c087ed3ec76def23c344"
  },
  "gist": {
   "data": {
    "description": "courses/ml1/churn.ipynb",
    "public": false
   },
   "id": "1292bacee4b6c087ed3ec76def23c344"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
